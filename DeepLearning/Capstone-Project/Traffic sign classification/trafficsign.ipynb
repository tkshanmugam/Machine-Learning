{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7829924-ff26-4982-803c-ee3349dac107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae868ba-4d45-4fbc-82f1-d70e0744a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            #sim = Image.fromarray(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd09cc-7f58-48ba-9856-42eff8448b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting lists into numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(data.shape, labels.shape)\n",
    "#Splitting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753f5ee-1f87-44bf-b273-1a3c0c438479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the labels into one hot encoding\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)\n",
    "\n",
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300eafa6-b142-4338-8924-b41c6941d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37bb5d-8029-478e-a0d6-d555634d7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))\n",
    "model.save(\"trafficsign.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b036f2-5ee9-47dc-b928-b243268ac1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting graphs for accuracy \n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3436c-a1ce-4022-9e55-17da8a21ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a486be3-8416-4577-9a37-2f377318e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing accuracy on test dataset\n",
    "y_test = pd.read_csv('Test.csv')\n",
    "\n",
    "# Extract labels and image paths\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "\n",
    "# Ensure labels are integers\n",
    "labels = labels.astype(int)\n",
    "\n",
    "# Preprocess images\n",
    "data = []\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30, 30))  # Make sure the size matches your model input\n",
    "    data.append(np.array(image))\n",
    "\n",
    "X_test = np.array(data)\n",
    "\n",
    "# Make predictions\n",
    "pred_probs = model.predict(X_test)  # Use predict instead of predict_classes\n",
    "pred = np.argmax(pred_probs, axis=1)  # Get class with highest probability\n",
    "\n",
    "# Ensure predictions are integers\n",
    "pred = pred.astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(labels, pred)\n",
    "print(\"Accuracy on test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed9c9d-4742-43c3-9fbb-03627deddecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
      "Speed limit (30km/h)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "General caution\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Speed limit (70km/h)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Speed limit (50km/h)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Traffic signals\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Road work\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model to classify signs\n",
    "model = load_model('trafficsign.h5')\n",
    "\n",
    "# Dictionary to label all traffic signs classes\n",
    "classes = {\n",
    "    1: 'Speed limit (20km/h)',\n",
    "    2: 'Speed limit (30km/h)',\n",
    "    3: 'Speed limit (50km/h)',\n",
    "    4: 'Speed limit (60km/h)',\n",
    "    5: 'Speed limit (70km/h)',\n",
    "    6: 'Speed limit (80km/h)',\n",
    "    7: 'End of speed limit (80km/h)',\n",
    "    8: 'Speed limit (100km/h)',\n",
    "    9: 'Speed limit (120km/h)',\n",
    "    10: 'No passing',\n",
    "    11: 'No passing veh over 3.5 tons',\n",
    "    12: 'Right-of-way at intersection',\n",
    "    13: 'Priority road',\n",
    "    14: 'Yield',\n",
    "    15: 'Stop',\n",
    "    16: 'No vehicles',\n",
    "    17: 'Veh > 3.5 tons prohibited',\n",
    "    18: 'No entry',\n",
    "    19: 'General caution',\n",
    "    20: 'Dangerous curve left',\n",
    "    21: 'Dangerous curve right',\n",
    "    22: 'Double curve',\n",
    "    23: 'Bumpy road',\n",
    "    24: 'Slippery road',\n",
    "    25: 'Road narrows on the right',\n",
    "    26: 'Road work',\n",
    "    27: 'Traffic signals',\n",
    "    28: 'Pedestrians',\n",
    "    29: 'Children crossing',\n",
    "    30: 'Bicycles crossing',\n",
    "    31: 'Beware of ice/snow',\n",
    "    32: 'Wild animals crossing',\n",
    "    33: 'End speed + passing limits',\n",
    "    34: 'Turn right ahead',\n",
    "    35: 'Turn left ahead',\n",
    "    36: 'Ahead only',\n",
    "    37: 'Go straight or right',\n",
    "    38: 'Go straight or left',\n",
    "    39: 'Keep right',\n",
    "    40: 'Keep left',\n",
    "    41: 'Roundabout mandatory',\n",
    "    42: 'End of no passing',\n",
    "    43: 'End no passing vehicle with a weight greater than 3.5 tons'\n",
    "}\n",
    "\n",
    "# Initialize GUI\n",
    "top = tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Traffic Sign Classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "\n",
    "label = Label(top, background='#CDCDCD', font=('arial', 15, 'bold'))\n",
    "sign_image = Label(top)\n",
    "\n",
    "def classify(file_path):\n",
    "    global label_packed\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((30, 30))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = np.array(image)\n",
    "    pred_probs = model.predict(image)\n",
    "    pred = np.argmax(pred_probs, axis=1)[0]\n",
    "    sign = classes.get(pred + 1, \"Unknown\")\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)\n",
    "\n",
    "def show_classify_button(file_path):\n",
    "    classify_b = Button(top, text=\"Classify Image\", command=lambda: classify(file_path), padx=10, pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white', font=('arial', 10, 'bold'))\n",
    "    classify_b.place(relx=0.79, rely=0.46)\n",
    "\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        uploaded = Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/2.25), (top.winfo_height()/2.25)))\n",
    "        im = ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image = im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "upload = Button(top, text=\"Upload an image\", command=upload_image, padx=10, pady=5)\n",
    "upload.configure(background='#364156', foreground='white', font=('arial', 10, 'bold'))\n",
    "upload.pack(side=BOTTOM, pady=50)\n",
    "\n",
    "sign_image.pack(side=BOTTOM, expand=True)\n",
    "label.pack(side=BOTTOM, expand=True)\n",
    "\n",
    "heading = Label(top, text=\"Check Traffic Sign\", pady=20, font=('arial', 20, 'bold'))\n",
    "heading.configure(background='#CDCDCD', foreground='#364156')\n",
    "heading.pack()\n",
    "\n",
    "top.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799fc5a-0936-4c18-bad6-f1bca9826e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
